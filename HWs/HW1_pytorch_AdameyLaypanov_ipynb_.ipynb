{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcF9My_FhLuk"
      },
      "source": [
        "# **HW 1. PyTorch practice**\n",
        "### Course: Deep Learning (DSBA and ICEF), 2025, HSE\n",
        "### Authors: Alexey Boldyrev, ML Teaching Team\n",
        "\n",
        "Issue Date: 29.01.2025\n",
        "\n",
        "Deadline: \\\n",
        "(Soft) 23:59 MSK 04.02.2025 \\\n",
        "(Hard) 18:00 MSK 05.02.2025\n",
        "\n",
        "Authors: Alexey Boldyrev, ML Teaching Team"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G64TptyJhLuo"
      },
      "source": [
        "### About the assignment\n",
        "\n",
        "The assignment is in two parts. The first part (PyTorch basics) is not assessed, but if you are not familiar with PyTorch or are unsure, we strongly recommend that you start with it. The second part (Practice) has graded and ungraded exercises on working with tensors and building your first neural network.\\\n",
        "The goal of the assignment is to gain practical skills in working with PyTorch.\n",
        "\n",
        "### Assessment and penalties\n",
        "Each of the tasks has a certain “cost” (indicated in brackets near the task). The maximum allowable grade for a task is 20 points.\n",
        "\n",
        "You may not turn in an assignment after a strict (Hard) deadline. In case of assigning an incomplete grade for a task due to errors, the reviewer has the opportunity to correct the work under the conditions specified in the response letter.\n",
        "\n",
        "The assignment is completed independently. “Similar” solutions are considered plagiarism and all students involved (including those who have been copied from) cannot receive more than 0 points for it. If you have found a solution to any of the assignments (or part of it) in an open source, you must provide a link to that source (most likely you will not be the only one who found it, so to exclude suspicion of plagiarism, a link to the source is required).\n",
        "\n",
        "If you used a generative model (large language model like ChatGPT, DeepSeek, built-in Colab generative AI, or similar) for finding a solution, you need to provide the link to the service used (browser verion, tg bot, etc.), network name, the prompt(s) used and how you evaluate the performance of this model. Without this reflection the home assignment won't be graded.\n",
        "\n",
        "### Format of submission\n",
        "Assignments are submitted through the Smart LMS system here https://edu.hse.ru/mod/assign/view.php?id=1544066. You should send a notebook with the completed assignment. Name the notebook itself in the format **HW1-pytorch-NameLastname.ipynb**, where Name and Lastname are your first and last name.\n",
        "\n",
        "For ease of checking yourself, calculate your maximum grade (based on the set of problems solved) and indicate it below.\n",
        "\n",
        "Score: **xx**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXlfHE_hLup"
      },
      "source": [
        "## 0. PyTorch basics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspired by https://nrehiew.github.io/blog/pytorch/"
      ],
      "metadata": {
        "id": "CnhT3CDa--Du"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wirAvJNxhLup"
      },
      "source": [
        "Load necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aQ2_j3nkhLuq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch uses its own data representation (i.e. **tensor** objects) for several important reasons that are key to its purpose as an efficient, flexible, and scalable deep learning framework.\n",
        "\n",
        "PyTorch's custom data representation enables\n",
        "- High performance on hardware accelerators.\n",
        "- Support for automatic differentiation.\n",
        "- Flexibility through dynamic computational graphs.\n",
        "- Advanced multidimensional data manipulation.\n",
        "- Multi-device scalability.\n",
        "\n",
        "These features make PyTorch tensors ideal for deep learning, unlike traditional Python data structures such as lists or arrays."
      ],
      "metadata": {
        "id": "FA8a-cnn0gFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of machine learning, a tensor is an *n*-dimensional matrix. OK, but what is a `torch.tensor`? More specifically, what actually happens when the following piece of code is executed: `a = torch.tensor(1.0, requires_grad=True)`? It turns out that PyTorch allocates the data on the heap and returns the pointer to that data as a shared pointer (see more [here](https://discuss.pytorch.org/t/where-does-torch-tensor-create-the-object-stack-or-heap/182753)). To better understand pointers in PyTorch, let's look at some examples."
      ],
      "metadata": {
        "id": "q8RTaJJl8faQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell creates a tensor with shape `(2, 6)`, two rows and six columns, containing values randomly distributed according to a normal distribution with mean zero and standard deviation one."
      ],
      "metadata": {
        "id": "fNtxji6Jgd2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.randn((2, 6))\n",
        "print(features)"
      ],
      "metadata": {
        "id": "r_ToDexwg0-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19495f84-7f62-446a-8901-94bb7d5fa20d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.1369, -0.0412,  0.7060,  1.1004, -0.2327,  0.3416],\n",
            "        [ 0.2624,  0.5259,  0.3270, -0.4666, -0.4540, -0.8650]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell creates another tensor with the same shape as the features, again containing values from a normal distribution."
      ],
      "metadata": {
        "id": "s560vhGohKO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.randn_like(features)\n",
        "print(weights)"
      ],
      "metadata": {
        "id": "1tAtv29HhMI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1900a4e-7d01-43fe-9b3b-df72dbd1b0e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3841, -0.8045, -1.1129,  0.7401, -0.8318,  0.7168],\n",
            "        [-1.8798,  3.0728,  0.6047,  0.6948,  0.0504,  0.1118]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch tensors can be added, multiplied, subtracted, etc., just like Numpy arrays. In general, you'll use PyTorch tensors pretty much the same way you use Numpy arrays."
      ],
      "metadata": {
        "id": "QZutF30jhZih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(9).reshape(3, 3) # 3x3 tensor\n",
        "print(a)"
      ],
      "metadata": {
        "id": "ZV7NQt8PmRFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352268a2-d1ab-42f6-d245-7915610c6b6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original and derived tensors in PyTorch are objects linked to the same memory area:"
      ],
      "metadata": {
        "id": "D0OfYkViyl-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.t() # Transpose\n",
        "b[0, 0] = 123\n",
        "print(a, '\\n\\n', b)"
      ],
      "metadata": {
        "id": "Wmb60ZeVypmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e501924a-073e-49c1-e103-318bcb0f7d16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[123,   1,   2],\n",
            "        [  3,   4,   5],\n",
            "        [  6,   7,   8]]) \n",
            "\n",
            " tensor([[123,   3,   6],\n",
            "        [  1,   4,   7],\n",
            "        [  2,   5,   8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `.t()` returns a pointer, which means that both a and b point to the same underlying data, and any changes to that underlying data can be seen from both pointers."
      ],
      "metadata": {
        "id": "gL_lk8o1zA2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare with:"
      ],
      "metadata": {
        "id": "IWba5f6QzVHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(9).reshape(3, 3) # torch.int64\n",
        "b = a.to(torch.float16) #\n",
        "b[0][0] = 42\n",
        "print(a[0][0].item(), b[0][0].item())\n",
        "print(a,'\\n\\n', b)"
      ],
      "metadata": {
        "id": "E89Sftf1mRQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0949251f-ffaf-4fd0-a705-1cb412bb4d1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 42.0\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]]) \n",
            "\n",
            " tensor([[42.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.]], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlulCwVKhLur"
      },
      "source": [
        "PyTorch needs to represent a `float16` differently to how `int64` is represented in memory. So in this example PyTorch needs to make a copy of the data and represent it differently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4wkVlIehLur"
      },
      "source": [
        "### PyTorch broadcasting\n",
        "\n",
        "If necessary, check the PyTorch [broadcasting semantics](https://pytorch.org/docs/stable/notes/broadcasting.html#general-semantics).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2]).reshape(1, 2) # 1 x 2\n",
        "b = torch.tensor([[3, 4], [5, 6]]) # 2 x 2\n",
        "c = torch.zeros((2, 2)) # we know that a + b gives a 2x2 tensor"
      ],
      "metadata": {
        "id": "-44pcjGr_CFZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuiDJiWF_ClY",
        "outputId": "ed3d5423-87de-49ac-d458-296b30952f96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2]])\n",
            "tensor([[3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c[0][0] = a[0][0] + b[0][0]\n",
        "c[0][1] = a[0][1] + b[0][1]\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx1HnC0T_Zxi",
        "outputId": "175b81e4-a3f9-4572-c5c5-dcfd7230029a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 6.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c[1][0] = a[0][0] + b[1][0]\n",
        "c[1][1] = a[0][1] + b[1][1]\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6v4JJki_i31",
        "outputId": "8df98699-c1a0-406c-fe35-040c032a63e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 6.],\n",
            "        [6., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a+b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwNDUdP__yM_",
        "outputId": "b3fd321c-e54d-4849-afa7-edebcc39ff44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 6],\n",
            "        [6, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BIuaYSvqhLus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9fec4f-9008-43b6-c080-7683e2c8dc98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "torch.equal(a + b, c) # true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication"
      ],
      "metadata": {
        "id": "AqHFyS9X_5TB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((3, 4, 1, 2)) # 3 x 4 x 1 x 2\n",
        "b = torch.randn((1, 2, 3)) # 1 x 2 x 3\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLP6F7MeAMY8",
        "outputId": "22ddc816-c091-4f54-f174-1892c30a719a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.1275, -1.1976]],\n",
            "\n",
            "         [[ 0.9557, -0.1067]],\n",
            "\n",
            "         [[-0.3287,  1.1247]],\n",
            "\n",
            "         [[-0.0341, -0.4208]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4082, -1.0361]],\n",
            "\n",
            "         [[ 0.1449,  0.9473]],\n",
            "\n",
            "         [[-0.0441,  0.0817]],\n",
            "\n",
            "         [[ 0.7565,  2.0654]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8078,  1.0138]],\n",
            "\n",
            "         [[ 0.6545,  0.4114]],\n",
            "\n",
            "         [[-1.1439, -1.0106]],\n",
            "\n",
            "         [[-1.4946, -0.3072]]]])\n",
            "tensor([[[ 0.7409,  0.6773,  1.9137],\n",
            "         [-1.2731, -1.2322,  0.5689]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.zeros((3, 4, 1, 3))\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2AZcXQ2B6zP",
        "outputId": "b3969022-d477-4049-82cb-d75e287dd18e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "\tprint(i)\n",
        "\tfor j in range(4):\n",
        "\t\tprint(j)\n",
        "\t\ta_slice = a[i][j]\n",
        "\t\tprint(a_slice)\n",
        "\t\tb_slice = b[0]\n",
        "\t\tprint(b_slice)\n",
        "\t\tc[i][j] = a_slice @ b_slice\n",
        "\n",
        "print(torch.matmul(a, b).shape, c.shape)"
      ],
      "metadata": {
        "id": "NgxuJauQ_8KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a67cd1-9f53-4283-f9b6-858ff1c33ee3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "tensor([[-0.1275, -1.1976]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "1\n",
            "tensor([[ 0.9557, -0.1067]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "2\n",
            "tensor([[-0.3287,  1.1247]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "3\n",
            "tensor([[-0.0341, -0.4208]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "1\n",
            "0\n",
            "tensor([[ 0.4082, -1.0361]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "1\n",
            "tensor([[0.1449, 0.9473]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "2\n",
            "tensor([[-0.0441,  0.0817]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "3\n",
            "tensor([[0.7565, 2.0654]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "2\n",
            "0\n",
            "tensor([[0.8078, 1.0138]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "1\n",
            "tensor([[0.6545, 0.4114]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "2\n",
            "tensor([[-1.1439, -1.0106]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "3\n",
            "tensor([[-1.4946, -0.3072]])\n",
            "tensor([[ 0.7409,  0.6773,  1.9137],\n",
            "        [-1.2731, -1.2322,  0.5689]])\n",
            "torch.Size([3, 4, 1, 3]) torch.Size([3, 4, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWs6ljrIhLus"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core of PyTorch is its automatic differentiation engine. In general terms, each time a differentiable operation between 2 tensors occurs, PyTorch will automatically build the entire computational graph through a callback function. The gradient of each tensor is then updated when `.backward()` is called. This is PyTorch's biggest abstraction. Often `.backward()` is called and we just hope that the gradients flow properly. In this section I will try to build some intuition for visualising gradient flows."
      ],
      "metadata": {
        "id": "aGsDDU6rGlpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# Define a function y = x^2\n",
        "y = x**2\n",
        "print(y)\n",
        "# Compute the gradient (dy/dx)\n",
        "y.backward()\n",
        "z = y.backward\n",
        "print(z)\n",
        "\n",
        "# x.grad will hold the derivative of y with respect to x\n",
        "print(x.grad)  # Output: tensor([4.])"
      ],
      "metadata": {
        "id": "Hv0g-0B5Hqbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2075afe-37a5-44ea-93eb-a8d953147010"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], requires_grad=True)\n",
            "tensor([4.], grad_fn=<PowBackward0>)\n",
            "<bound method Tensor.backward of tensor([4.], grad_fn=<PowBackward0>)>\n",
            "tensor([4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common problem in trying to understand backpropagation is that most people understand derivatives and the chain rule for scalars, but how this translates to higher dimensional tensors is not particularly obvious.\n",
        "\n",
        "Thinking about gradients from this local scalar perspective has the added benefit of making the effect of tensor operations on gradients intuitive. For example, operations such as `.reshape()`, `.transpose()`, `.cat()` and `.split()` do not affect the single value and its gradient on a local scale. It follows naturally that the effect of these operations on the gradient tensor of a tensor is the operation itself. For example, flattening a tensor with `.reshape(-1)` will have the same effect on its gradient as calling `.reshape(-1)`."
      ],
      "metadata": {
        "id": "KYhklXjXHree"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.tensor([[1.0, 2.0], [3.0, 4.0]], requires_grad=True)  # Shape: (2, 2)\n",
        "\n",
        "# Define a vector-valued function: f(z) = z^3 + 2z\n",
        "f = z**3 + 2 * z  # Element-wise\n",
        "print(f)\n",
        "\n",
        "# Compute gradients by summing over all outputs (scalarization)\n",
        "# The .backward() method requires scalar output, hence `sum()`\n",
        "f.sum().backward()\n",
        "\n",
        "\n",
        "# Gradients of f w.r.t the input z\n",
        "print(z.grad)  # Contains derivatives for each element in z"
      ],
      "metadata": {
        "id": "0rwEkgRxIQEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa14a04-2ac7-4a58-9496-a46a6c61c861"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3., 12.],\n",
            "        [33., 72.]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 5., 14.],\n",
            "        [29., 50.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch also supports higher-order derivatives (e.g., second or third derivatives). To compute these, you need to set `create_graph=True` for the first derivative computation. For example:"
      ],
      "metadata": {
        "id": "z1JvoyxJIac7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "f = x**3\n",
        "\n",
        "# Compute first derivative df/dx using autograd.grad\n",
        "first_derivative = torch.autograd.grad(f, x, create_graph=True)[0]\n",
        "\n",
        "print(\"First derivative:\", first_derivative)\n",
        "\n",
        "# Compute second derivative d^2f/dx^2\n",
        "second_derivative = torch.autograd.grad(first_derivative, x)[0]\n",
        "\n",
        "print(\"Second derivative:\", second_derivative)"
      ],
      "metadata": {
        "id": "Qs6xwnhuIdCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665ebad5-9050-4777-d351-13a13227a478"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First derivative: tensor([12.], grad_fn=<MulBackward0>)\n",
            "Second derivative: tensor([12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute the Jacobian (partial derivatives of each output w.r.t each input):"
      ],
      "metadata": {
        "id": "eFK1Mx2nJI3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "\n",
        "# Define a vector-valued function\n",
        "y = torch.stack([x[0]**2, x[1]**3])  # Outputs: [x[0]^2, x[1]^3]\n",
        "\n",
        "# Compute Jacobian (manually populate each row)\n",
        "jacobian = []\n",
        "for i in range(y.size(0)):\n",
        "    x.grad = None  # Clear previous gradients\n",
        "    y[i].backward(retain_graph=True)  # Compute partial derivatives\n",
        "    jacobian.append(x.grad.clone())  # Store the gradient for output i\n",
        "\n",
        "jacobian = torch.stack(jacobian)\n",
        "\n",
        "print(\"Jacobian matrix:\")\n",
        "print(jacobian)  # Displays the partial derivatives"
      ],
      "metadata": {
        "id": "Sv9apb72JJtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7bdf01-eb0d-4a00-a32e-74e78039255f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix:\n",
            "tensor([[ 2.,  0.],\n",
            "        [ 0., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Practice"
      ],
      "metadata": {
        "id": "OsQZKYEoFP5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Documentation\n",
        "Please use the PyTorch documentation in case of difficulties:\n",
        "* The documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor)\n",
        "* The documentation on [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics)\n"
      ],
      "metadata": {
        "id": "hgeUaWR4D3xV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Create a random tensor with shape `(5, 5)`."
      ],
      "metadata": {
        "id": "vky1ZFTQFj4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1= torch.randn((5, 5))\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "1ZU1IDQwF40N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcb573c-8fcd-4839-b9e9-d5ceab7e3790"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1950,  0.7289, -0.6164, -2.0146, -1.1022],\n",
            "        [ 0.7565, -0.0824,  0.0985, -1.0250,  0.4488],\n",
            "        [ 0.1991,  0.2152, -1.2486,  1.6180,  3.1256],\n",
            "        [-0.7890, -1.2829, -1.5522, -1.2321,  0.8292],\n",
            "        [-0.8057, -1.7435, -0.6823, -0.1751,  0.7122]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Perform matrix multiplication of the resulting tensor with another random tensor of shape `(1, 5)`.\n",
        "Hint: you may have to transpose the second tensor."
      ],
      "metadata": {
        "id": "m5swfTluGCGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.randn((1,5))\n",
        "print(t2)"
      ],
      "metadata": {
        "id": "O4n_AwyjHGNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fe9fa5-4fe4-4c1e-ae70-7693644da479"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.9558, -0.1168,  1.0211,  0.6961,  0.1479]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we cant multiply mat5x5 with mat1x5-lets transpose matrix 1x5 to be matrix 5x1"
      ],
      "metadata": {
        "id": "oiVVoVjyImo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = t2.T\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDHxX3KGI2fQ",
        "outputId": "d2a71366-986d-4e42-b1fd-5851a3f1a875"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.9558],\n",
            "        [-0.1168],\n",
            "        [ 1.0211],\n",
            "        [ 0.6961],\n",
            "        [ 0.1479]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = t1 @ t2\n",
        "print(t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGjBuFFNINP5",
        "outputId": "b010b1bb-2f23-4d23-a4fa-d2a7a26a89f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.6613],\n",
            "        [-2.0165],\n",
            "        [-0.1010],\n",
            "        [-0.6270],\n",
            "        [ 1.0663]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Set the random seed to `42` and repeat code in two previous cells.\n",
        "The output should be:\\\n",
        "```tensor([[1.1697],\n",
        "        [0.9278],\n",
        "        [0.9534],\n",
        "        [0.6976],\n",
        "        [0.7460]])```"
      ],
      "metadata": {
        "id": "lHVza-w5HymK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdQMchUSN20d",
        "outputId": "7dcad697-4472-4e1d-feef-957cd135e8ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cc384aadff0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.rand(5, 5)\n",
        "t2 = torch.rand(1, 5)\n",
        "result = t1 @ t2.T\n",
        "print(t1 @ t2.T)"
      ],
      "metadata": {
        "id": "7wGvpJ8mIH1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad62ed1c-0d17-4999-cfa2-311e8a38a4c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.1697],\n",
            "        [0.9278],\n",
            "        [0.9534],\n",
            "        [0.6976],\n",
            "        [0.7460]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Set random seed on the GPU.\n",
        "\n",
        "Hint: You'll need to read the [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics) documentation for this."
      ],
      "metadata": {
        "id": "y0j-wOBUJ7sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "dL3xPknOKTqu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Create two random tensors of shape `(3, 4)` and send them both to the GPU. Set random seed `123` when creating the tensors (this doesn't have to be the GPU random seed).\n",
        "\n",
        "Hint: The output should contain `device='cuda:0'`.\n",
        "Hint: How to access GPU in Colab?\n",
        "Setting up the Runtime: In Google Colab, go to the \"Runtime\" menu and select \"Change runtime type.\" A dialog box will appear where you can choose the runtime type and hardware accelerator. Select \"T4 GPU\" as the hardware accelerator and click \"Save.\" This step ensures that your Colab notebook is configured to use the GPU.\n",
        "\n"
      ],
      "metadata": {
        "id": "KiztDqPBMf92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "t1 = torch.rand(3, 4)\n",
        "t2 = torch.rand(3, 4)\n",
        "check = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "t1 = t1.to(check)\n",
        "t2 = t2.to(check)"
      ],
      "metadata": {
        "id": "Iphtzk8UN8Zq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Сheck:{t1.device}, {t2.device}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeXAhJQXXndX",
        "outputId": "50d220b5-c411-42a5-c181-d602c1608900"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сheck:cuda:0, cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Perform a matrix multiplication on the tensors you created in previous cell.\n",
        "Hint: you may have to adjust the shapes of one of the tensors.\n"
      ],
      "metadata": {
        "id": "rhy9lfR2OJn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2_T = t2.T\n",
        "mul = t1 @ t2_T\n",
        "print(mul)"
      ],
      "metadata": {
        "id": "XOLT8xgaOsV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f8eced-346a-4101-9cc8-d17f41637ed9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4802, 1.0135, 1.3960],\n",
            "        [0.2604, 0.8456, 0.7648],\n",
            "        [0.5326, 1.1972, 1.4639]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Find the minimum and maximum values of the output of previous cell."
      ],
      "metadata": {
        "id": "EYNmDRMJPC0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Maximum-{mul.max()}')\n",
        "print(f'Minimum-{mul.min()}')"
      ],
      "metadata": {
        "id": "dbK9-0ekPN0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc20a2b-0dd3-4498-ab00-486a289c3a1c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum-1.4639008045196533\n",
            "Minimum-0.2603716552257538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Find the indices of these minimum and maximum values."
      ],
      "metadata": {
        "id": "Zqi0bF0DPWq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Maximum-{torch.argmax(mul)}')\n",
        "print(f'Minimum-{torch.argmin(mul)}')\n",
        "print('-' * 10)\n",
        "print(f'Maximum-{torch.unravel_index(torch.argmax(mul), mul.shape)}')\n",
        "print(f'Minimum-{torch.unravel_index(torch.argmin(mul), mul.shape)}')"
      ],
      "metadata": {
        "id": "mrFKBNZ6Pj0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab72f2a2-052e-493f-829e-0f8a53b6588c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum-8\n",
            "Minimum-3\n",
            "----------\n",
            "Maximum-(tensor(2, device='cuda:0'), tensor(2, device='cuda:0'))\n",
            "Minimum-(tensor(1, device='cuda:0'), tensor(0, device='cuda:0'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2 points] Make a random tensor with shape `(1, 1, 1, 8)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(8)`. Set the seed to `999` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ],
      "metadata": {
        "id": "58g_O7LAQcxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(999)\n",
        "\n",
        "t = torch.rand(1, 1, 1, 8)\n",
        "print(\"Original: \\n\", t)\n",
        "print(\"Shape:\", t.shape)\n",
        "print('-' * 15)\n",
        "t = t.squeeze()\n",
        "print(\"fixed: \\n\", t)\n",
        "print(\"Shape:\", t.shape)"
      ],
      "metadata": {
        "id": "XG3kPy8oQ004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ac186b-3085-437a-acad-9cdff4f6ca16"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: \n",
            " tensor([[[[0.6776, 0.6531, 0.0457, 0.9424, 0.4925, 0.9985, 0.7585, 0.0317]]]])\n",
            "Shape: torch.Size([1, 1, 1, 8])\n",
            "---------------\n",
            "fixed: \n",
            " tensor([0.6776, 0.6531, 0.0457, 0.9424, 0.4925, 0.9985, 0.7585, 0.0317])\n",
            "Shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Print the index of the maximum value of the second tensor."
      ],
      "metadata": {
        "id": "bSTu45lMRkwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Maximum-{torch.argmax(t)}')"
      ],
      "metadata": {
        "id": "0ZyDX9yVRv5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bf9d51-e9ec-41ac-d8aa-4dd50745a381"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum-5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your first neural network\n"
      ],
      "metadata": {
        "id": "gKI_cFegJZng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise you will implement a small neural network with two linear layers. The first layer takes an eight-dimensional input and the last layer outputs a one-dimensional tensor.\n",
        "The following exercices are inspired by the DataCamp course [Introduction to Deep Learning with PyTorch](https://app.datacamp.com/learn/courses/introduction-to-deep-learning-with-pytorch)."
      ],
      "metadata": {
        "id": "dskygzU9N9JG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Create a neural network of **two linear layers** that takes `input_tensor` as input, representing `8` features, and outputs a tensor of dimensions `1`.\n",
        "Hint: use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) and [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)."
      ],
      "metadata": {
        "id": "FSiXrpUvN_zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[1, 5, 4, 7, 3, 6, 0, 2]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 8),  # я не понял какой аутпут должен быть у первого слоя-поэтому оставил 8\n",
        "    nn.Linear(8, 1)\n",
        ")\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "zVFHvZHlNjOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3562a7-9403-46dd-f342-be4d312d19d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2518]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Create a [`torch.nn.Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) and apply it on `input_tensor` to generate a probability for a binary classification task."
      ],
      "metadata": {
        "id": "z2UPUEiTTyNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor([[1.3]])\n",
        "\n",
        "sigmoid = nn.Sigmoid()\n",
        "probability = sigmoid(input_tensor)\n",
        "\n",
        "print(probability)"
      ],
      "metadata": {
        "id": "sqLhiYvCT3t8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acd140e-fe98-4727-e2df-e52dc5a253a7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7858]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] Create a [`torch.nn.Softmax`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) and apply it on `input_tensor` to generate a probability for a multiclass classification task."
      ],
      "metadata": {
        "id": "nrMRn6INVgMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.tensor([[6.6, -3.2, -4.3, 0.3, -0.7, -4.7]])\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "probabilities = softmax(input_tensor)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "a9kAiY3hTSsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647398d9-d3e0-4233-e4c8-1ec15c1609e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9741e-01, 5.5308e-05, 1.8410e-05, 1.8315e-03, 6.7379e-04, 1.2341e-05]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [0 points] How can you avoid the following warning message when calling the softmax function from PyTorch?\n",
        "\n",
        "> UserWarning: Implicit dimension choice for softmax has been deprecated.\n",
        "\n"
      ],
      "metadata": {
        "id": "vMsMLm0QWJah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Use dim=1 to insure thaw we are working with features dimension**\n"
      ],
      "metadata": {
        "id": "UERx4fcek9wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks for Classification and Regression"
      ],
      "metadata": {
        "id": "ijdpDwEn6i03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2 points] Create a neural network that takes a tensor of dimension `1x8` as input and returns an output of the correct shape for binary classification."
      ],
      "metadata": {
        "id": "yvsqtcVVwHwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[1, 5, 4, 7, 3, 6, 0, 2]])\n",
        "\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "oXIZQDMkwS8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9daf0c-b105-4b16-d50a-896f18cb4087"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8761]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2 points] Create a 4-layer linear neural network compatible with input_tensor as input and a regression value as output."
      ],
      "metadata": {
        "id": "iYg4Pt2EyYVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[1, 5, 4, 7, 3, 6, 0, 2, 6, 2]])\n",
        "\n",
        "# сделал условное уменьшение размера признаков ибо не знаю как правильно тут :D\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 8),\n",
        "    nn.Linear(8, 6),\n",
        "    nn.Linear(6, 4),\n",
        "    nn.Linear(4, 1)\n",
        ")\n",
        "\n",
        "\n",
        "output = model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "bMN4ndYnyvtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3678439-4fb4-42d8-8e52-e5c1df6b88e2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0894]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Create a one-hot encoded vector of the ground truth label `y` using [`torch.nn.functional.one_hot`](https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html)."
      ],
      "metadata": {
        "id": "alY7CVjYzOhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = 1\n",
        "num_classes = 4\n",
        "\n",
        "one_hot = F.one_hot(torch.tensor(y), num_classes=num_classes)"
      ],
      "metadata": {
        "id": "4m1a5bQZzVhl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2 points] Calculate the cross entropy loss using the one-hot encoded vector of the ground truth label `y`, with `4` features (one for each class)."
      ],
      "metadata": {
        "id": "Kz3qoYAAz2qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "y = [2]\n",
        "scores = torch.tensor([[3.1, -5.0, 1.8, 4.3]])\n",
        "\n",
        "ohe = F.one_hot(torch.tensor(y), num_classes=4)\n",
        "ohe = ohe.float()\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "loss = criterion(scores, ohe)\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "f00cdahH0EF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739fa11f-8bde-4e71-ab9d-e112aaf86165"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.8245)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Accessing the model parameters.\n",
        "Hint: model parameters are weights and biases.\\\n",
        "Hint: use [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) documentation.\\\n",
        "Hint: try to discover [PyTorch discussion forum](https://discuss.pytorch.org/t/access-weights-of-a-specific-module-in-nn-sequential/3627)."
      ],
      "metadata": {
        "id": "kF3LyK8K1moJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(16, 8),\n",
        "                      nn.Linear(8, 4)\n",
        "                     )\n",
        "\n",
        "weight_0 = model[0].weight\n",
        "bias_1 = model[1].bias\n",
        "\n",
        "\n",
        "print(weight_0, bias_1)"
      ],
      "metadata": {
        "id": "8oF_In8b3q0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c054cb-b7fd-4cec-d46f-5d6a84606fa6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0650, -0.1691,  0.2195, -0.1818,  0.1693, -0.2301, -0.1864,  0.0435,\n",
            "         -0.0817,  0.2321,  0.2254, -0.2284, -0.0452, -0.0728, -0.1676,  0.0484],\n",
            "        [-0.0461,  0.0330, -0.1811,  0.1718,  0.1790, -0.0036, -0.0160,  0.1063,\n",
            "         -0.1950, -0.1921, -0.0919,  0.0159,  0.2449,  0.2384,  0.1306, -0.0911],\n",
            "        [-0.2396,  0.1677, -0.2184,  0.0946, -0.0969, -0.0373, -0.1033,  0.0782,\n",
            "          0.1053,  0.1502,  0.0607,  0.0010,  0.0079, -0.1084, -0.0202,  0.1200],\n",
            "        [-0.1736,  0.2232,  0.2257,  0.1896, -0.2084, -0.1083,  0.1057,  0.0876,\n",
            "         -0.1075,  0.1114, -0.0726, -0.1333, -0.0332,  0.0384,  0.0225, -0.2013],\n",
            "        [ 0.2192,  0.1386,  0.2435,  0.1542, -0.1793,  0.1354, -0.0907, -0.0218,\n",
            "         -0.1648, -0.2149,  0.0522,  0.1983, -0.1658,  0.2426,  0.1634,  0.0017],\n",
            "        [ 0.0899, -0.0246,  0.2204, -0.2235, -0.1836,  0.2353, -0.0810, -0.2213,\n",
            "          0.0012, -0.0274,  0.2292, -0.1078, -0.2320,  0.1670, -0.0671, -0.1283],\n",
            "        [ 0.1582, -0.1928,  0.2101,  0.0984,  0.1087,  0.2410, -0.1524,  0.1917,\n",
            "         -0.1277,  0.0679,  0.2437, -0.0384,  0.1410,  0.2018,  0.0064, -0.0794],\n",
            "        [ 0.1669, -0.2126, -0.0208,  0.0598,  0.2432, -0.1312, -0.0986, -0.2271,\n",
            "         -0.1527, -0.1635,  0.0416, -0.1975,  0.0872, -0.2493, -0.1046, -0.1398]],\n",
            "       requires_grad=True) Parameter containing:\n",
            "tensor([-0.2189, -0.2151,  0.0156, -0.1738], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [3 point] Create a 3-layer neural network.\n",
        "\n"
      ],
      "metadata": {
        "id": "dkVcOpLJ4QLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.Tensor([[1, 5, 4, 7, 3, 6, 0, 2, 6, 2, 4, 1, 4, 0, 5, 12]])\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(16, 8),\n",
        "    nn.Linear(8, 4),\n",
        "    nn.Linear(4, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "\n",
        "prediction = model(input_tensor)\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "target = torch.tensor([[1., 0.]])\n",
        "\n",
        "loss = criterion(prediction, target)\n",
        "\n",
        "\n",
        "loss.backward()\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "id": "kt4_rCUu_KAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c199ffb0-939e-48a2-8d07-aa02f7d5d7cd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor([[0.2097, 0.7903]], grad_fn=<SoftmaxBackward0>)\n",
            "Loss: tensor(1.0250, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2 points] Update the weights of the first layer using the gradients scaled by the learning rate `0.001`."
      ],
      "metadata": {
        "id": "aagrXWMeDmzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "\n",
        "weight = model[0].weight\n",
        "print(weight)\n",
        "\n",
        "grads = model[0].weight.grad\n",
        "with torch.no_grad():\n",
        "    weight -= lr * grads\n",
        "print(weight)\n"
      ],
      "metadata": {
        "id": "qpWTEfGx4VdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33113f23-fbf2-49d3-e56f-7dc5236ec41d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2480, -0.1458,  0.1999, -0.0229,  0.1366,  0.2351, -0.1843,  0.0115,\n",
            "          0.0452,  0.0154, -0.0792, -0.1693, -0.1519, -0.1825, -0.0966,  0.2236],\n",
            "        [ 0.0460, -0.1317,  0.2442,  0.0726,  0.1820, -0.0207,  0.0685, -0.1216,\n",
            "          0.0282,  0.0315,  0.1285,  0.1125,  0.1011,  0.0474, -0.1298,  0.0819],\n",
            "        [ 0.2447,  0.1693,  0.2194,  0.2487, -0.0641,  0.1796,  0.0121,  0.1662,\n",
            "         -0.1202, -0.0981, -0.1119,  0.1198,  0.0352,  0.1727, -0.1446,  0.1442],\n",
            "        [-0.1537,  0.0586, -0.0470,  0.0703,  0.2457, -0.0713,  0.1364, -0.0197,\n",
            "         -0.2254,  0.0879, -0.1380, -0.1945,  0.1994,  0.0540,  0.0227,  0.0071],\n",
            "        [ 0.0044,  0.2260, -0.1922,  0.1138,  0.1870,  0.0366, -0.2456, -0.1633,\n",
            "          0.2149, -0.2070,  0.2131,  0.0132, -0.1513,  0.2164,  0.1883, -0.0600],\n",
            "        [ 0.0658, -0.2168, -0.0010,  0.0626,  0.1958,  0.0964, -0.0696,  0.1542,\n",
            "          0.2296, -0.0402,  0.1443, -0.0332, -0.0478, -0.2487,  0.0484,  0.0335],\n",
            "        [-0.1268, -0.1081, -0.0090,  0.0715, -0.0069,  0.1408, -0.2390,  0.1468,\n",
            "         -0.0382, -0.2268, -0.0262,  0.0510,  0.0629,  0.2224,  0.1394,  0.0237],\n",
            "        [ 0.1315,  0.0244, -0.2464,  0.1722,  0.2229,  0.2174,  0.2324,  0.1891,\n",
            "         -0.1527,  0.2201, -0.1586,  0.0606, -0.0841, -0.0336,  0.1469, -0.1709]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.2480, -0.1457,  0.2000, -0.0227,  0.1367,  0.2353, -0.1843,  0.0115,\n",
            "          0.0454,  0.0155, -0.0791, -0.1693, -0.1518, -0.1825, -0.0965,  0.2240],\n",
            "        [ 0.0460, -0.1319,  0.2441,  0.0724,  0.1819, -0.0209,  0.0685, -0.1217,\n",
            "          0.0280,  0.0314,  0.1283,  0.1125,  0.1010,  0.0474, -0.1300,  0.0815],\n",
            "        [ 0.2447,  0.1691,  0.2193,  0.2485, -0.0642,  0.1794,  0.0121,  0.1662,\n",
            "         -0.1203, -0.0981, -0.1120,  0.1198,  0.0351,  0.1727, -0.1447,  0.1439],\n",
            "        [-0.1537,  0.0585, -0.0471,  0.0702,  0.2457, -0.0714,  0.1364, -0.0198,\n",
            "         -0.2255,  0.0879, -0.1381, -0.1945,  0.1994,  0.0540,  0.0227,  0.0069],\n",
            "        [ 0.0044,  0.2261, -0.1921,  0.1139,  0.1870,  0.0367, -0.2456, -0.1633,\n",
            "          0.2150, -0.2070,  0.2132,  0.0132, -0.1512,  0.2164,  0.1883, -0.0598],\n",
            "        [ 0.0657, -0.2170, -0.0011,  0.0624,  0.1958,  0.0962, -0.0696,  0.1541,\n",
            "          0.2294, -0.0403,  0.1442, -0.0332, -0.0479, -0.2487,  0.0483,  0.0331],\n",
            "        [-0.1269, -0.1083, -0.0092,  0.0712, -0.0071,  0.1406, -0.2390,  0.1467,\n",
            "         -0.0385, -0.2269, -0.0264,  0.0510,  0.0627,  0.2224,  0.1392,  0.0232],\n",
            "        [ 0.1315,  0.0242, -0.2466,  0.1720,  0.2228,  0.2172,  0.2324,  0.1890,\n",
            "         -0.1529,  0.2200, -0.1588,  0.0605, -0.0843, -0.0336,  0.1467, -0.1714]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [1 point] Update the model's parameters using the [`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) optimizer and the learning rate `0.001`."
      ],
      "metadata": {
        "id": "vju07zzBFL4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, input_tensor, target, criterion, optimizer, n_epoch):\n",
        "    for epoch in range(n_epoch):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(input_tensor)\n",
        "        loss = criterion(y_pred, target)\n",
        "        print(f'Epoch {epoch+1}/{n_epoch}, Loss = {loss.item()}')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "teL23tdETtNa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "#optimizer.zero_grad()\n",
        "#prediction = model(input_tensor)\n",
        "#loss = criterion(prediction, target)\n",
        "#loss.backward()\n",
        "#optimizer.step()\n",
        "#optimizer.zero_grad()\n",
        "\n",
        "#print(\"Final Prediction:\", prediction)\n",
        "#print(\"Final Loss:\", loss.item())"
      ],
      "metadata": {
        "id": "RmnIOzBSFabG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eec0e0-6157-4dd5-801d-5d4839d1fe7b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Prediction: tensor([[0.2121, 0.7879]], grad_fn=<SoftmaxBackward0>)\n",
            "Final Loss: 1.0218780040740967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(16, 8),\n",
        "    nn.Linear(8, 4),\n",
        "    nn.Linear(4, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "input_tensor = torch.Tensor([[1, 5, 4, 7, 3, 6, 0, 2, 6, 2, 4, 1, 4, 0, 5, 12]])\n",
        "target = torch.tensor([1])\n",
        "\n",
        "model = train(model, input_tensor, target, criterion, optimizer, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7BCV1fjVFix",
        "outputId": "7b9924f7-4359-430f-9b91-5d957f2db0f0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss = 0.547433614730835\n",
            "Epoch 2/20, Loss = 0.5449258685112\n",
            "Epoch 3/20, Loss = 0.5424408316612244\n",
            "Epoch 4/20, Loss = 0.5399786829948425\n",
            "Epoch 5/20, Loss = 0.5375396013259888\n",
            "Epoch 6/20, Loss = 0.5351235866546631\n",
            "Epoch 7/20, Loss = 0.532730758190155\n",
            "Epoch 8/20, Loss = 0.5303610563278198\n",
            "Epoch 9/20, Loss = 0.5280147194862366\n",
            "Epoch 10/20, Loss = 0.52569180727005\n",
            "Epoch 11/20, Loss = 0.5233920812606812\n",
            "Epoch 12/20, Loss = 0.5211158990859985\n",
            "Epoch 13/20, Loss = 0.5188630819320679\n",
            "Epoch 14/20, Loss = 0.5166337490081787\n",
            "Epoch 15/20, Loss = 0.5144277811050415\n",
            "Epoch 16/20, Loss = 0.5122451782226562\n",
            "Epoch 17/20, Loss = 0.510085940361023\n",
            "Epoch 18/20, Loss = 0.5079500675201416\n",
            "Epoch 19/20, Loss = 0.5058375597000122\n",
            "Epoch 20/20, Loss = 0.5037481188774109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNfiA56BVoHC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xQjV9BuhLu6"
      },
      "source": [
        "That's all for this PyTorch practice.\n",
        "\n",
        "**Don't forget to rename the jupyter notebook to HW1-pytorch-NameLastname.ipynb, where Name and Lastname are your first and last name. Then send a jupyter notebook file to SmartLMS.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}